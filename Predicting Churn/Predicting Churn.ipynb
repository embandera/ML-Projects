{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Predicting Churn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeQZGX2aOApF"
      },
      "source": [
        "# Predicting Churn (Supervised Learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN7fF2-OOApF"
      },
      "source": [
        "Our dataset shows that clients at the bank we represent are leaving: little by little, chipping away every month. In response, the bank has figured out that it is cheaper to save the existing clients rather than to attract new ones. We have been tasked to try and predict whether a customer will leave the bank soon. Our dataset shows clients’ past behavior and termination of contracts with the bank. \n",
        "\n",
        "In this report, I detail how we can test diffrerent models, such as a binary logistical regression model, and seek  the maximum possible F1 score. This type of problem is defined as a supervised learning classification problem, since this dataset has features along with a corresponding target (is labeled). \n",
        "\n",
        "I also write checklists to serve as reminders for possible steps to take.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbdOvC5_OApG"
      },
      "source": [
        "Data Details\n",
        "* Features \n",
        "    * RowNumber — data string index\n",
        "    * CustomerId — unique customer identifier \n",
        "    * Surname — surname\n",
        "    * CreditScore — credit score\n",
        "    * Geography — country of residence\n",
        "    * Gender — gender\n",
        "    * Age — age\n",
        "    * Tenure — period of maturation for a customer’s fixed deposit (years)\n",
        "    * Balance — account balance\n",
        "    * NumOfProducts — number of banking products used by the customer\n",
        "    * HasCrCard — customer has a credit card\n",
        "    * IsActiveMember — customer’s activeness\n",
        "    * EstimatedSalary — estimated salary\n",
        "* Target\n",
        "    * Exited — сustomer has left"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg06Q1HJOApG"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIsEpZ5bOApH"
      },
      "source": [
        "- [x] Import popular libraries, including a handful of classifiers to train your data with. Return to import libraries as needed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf9rZek5OApH"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import make_scorer\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XpNYttvOApI"
      },
      "source": [
        "## Inspect the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yilO1AUCOApI"
      },
      "source": [
        "- [x] Import your data\n",
        "- [x] Inspect your data. Consider using: \n",
        "        - info()\n",
        "        - head()\n",
        "        - tail()\n",
        "        - value_counts(). Can also help you to locate values MCAR, MAR, MNAR. \n",
        "        - describe() \n",
        "        - duplicated() \n",
        "        - shape() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txHeSWOIOApJ"
      },
      "source": [
        "df = pd.read_csv('/content/Churn.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbMCdvXaOApJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b599c6b8-4e26-4e7a-bf8c-c8cca253cdb6"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           9091 non-null   float64\n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(3), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6w5zedZOApK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "2d64163f-9fd9-4a2f-905e-348586ebf242"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>9091.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5000.50000</td>\n",
              "      <td>1.569094e+07</td>\n",
              "      <td>650.528800</td>\n",
              "      <td>38.921800</td>\n",
              "      <td>4.997690</td>\n",
              "      <td>76485.889288</td>\n",
              "      <td>1.530200</td>\n",
              "      <td>0.70550</td>\n",
              "      <td>0.515100</td>\n",
              "      <td>100090.239881</td>\n",
              "      <td>0.203700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2886.89568</td>\n",
              "      <td>7.193619e+04</td>\n",
              "      <td>96.653299</td>\n",
              "      <td>10.487806</td>\n",
              "      <td>2.894723</td>\n",
              "      <td>62397.405202</td>\n",
              "      <td>0.581654</td>\n",
              "      <td>0.45584</td>\n",
              "      <td>0.499797</td>\n",
              "      <td>57510.492818</td>\n",
              "      <td>0.402769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.556570e+07</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.580000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2500.75000</td>\n",
              "      <td>1.562853e+07</td>\n",
              "      <td>584.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51002.110000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5000.50000</td>\n",
              "      <td>1.569074e+07</td>\n",
              "      <td>652.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>97198.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100193.915000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7500.25000</td>\n",
              "      <td>1.575323e+07</td>\n",
              "      <td>718.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>127644.240000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>149388.247500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>1.581569e+07</td>\n",
              "      <td>850.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>250898.090000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>199992.480000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         RowNumber    CustomerId  ...  EstimatedSalary        Exited\n",
              "count  10000.00000  1.000000e+04  ...     10000.000000  10000.000000\n",
              "mean    5000.50000  1.569094e+07  ...    100090.239881      0.203700\n",
              "std     2886.89568  7.193619e+04  ...     57510.492818      0.402769\n",
              "min        1.00000  1.556570e+07  ...        11.580000      0.000000\n",
              "25%     2500.75000  1.562853e+07  ...     51002.110000      0.000000\n",
              "50%     5000.50000  1.569074e+07  ...    100193.915000      0.000000\n",
              "75%     7500.25000  1.575323e+07  ...    149388.247500      0.000000\n",
              "max    10000.00000  1.581569e+07  ...    199992.480000      1.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aLcF8zyOApL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d64538a0-af45-414a-c485-b8fb80925434"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1.0</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8.0</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2.0</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl98ZtE9OApL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed1e915-0970-4b8c-95fd-95330beaba2c"
      },
      "source": [
        "print(\"\\033[1m\" + 'We have {} duplicated rows.'.format(df.duplicated().sum()) + \"\\033[0m\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mWe have 0 duplicated rows.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwbdJEocOApM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "d52feea0-0ced-42b3-d25d-b20962ef45e0"
      },
      "source": [
        "df_nulls = pd.DataFrame(df.isna().sum(),columns=['Missing Values'])\n",
        "df_nulls['Percent of Nulls'] = round(df_nulls['Missing Values'] / df.shape[0],4) *100\n",
        "df_nulls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Values</th>\n",
              "      <th>Percent of Nulls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RowNumber</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CustomerId</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Surname</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CreditScore</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Geography</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tenure</th>\n",
              "      <td>909</td>\n",
              "      <td>9.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balance</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumOfProducts</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HasCrCard</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsActiveMember</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exited</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Missing Values  Percent of Nulls\n",
              "RowNumber                     0              0.00\n",
              "CustomerId                    0              0.00\n",
              "Surname                       0              0.00\n",
              "CreditScore                   0              0.00\n",
              "Geography                     0              0.00\n",
              "Gender                        0              0.00\n",
              "Age                           0              0.00\n",
              "Tenure                      909              9.09\n",
              "Balance                       0              0.00\n",
              "NumOfProducts                 0              0.00\n",
              "HasCrCard                     0              0.00\n",
              "IsActiveMember                0              0.00\n",
              "EstimatedSalary               0              0.00\n",
              "Exited                        0              0.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrvg8Va_OApM"
      },
      "source": [
        "Our inspection of the data shows that 9% of values are missing when it comes to data on Tenure for a client (period of maturation for a customer’s fixed deposit in years). We'll choose to fill this missing value in our next phase of Data Prepocessing. Other than missing values, we also notice that we have some categorical variables which we'll have to transform before testing the logistical regression model (random forest and decision tree can take categorical variables)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnhTTTa-OApM"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WvRGcujOApN"
      },
      "source": [
        "Before testing any models, we want to make sure that our dataset is as clean as possible. We'll use this checklist to help guide us through any transformations we might need to make. \n",
        "- [x] Deal with Missing Values \n",
        "- [ ] Eliminate Outliers \n",
        "- [ ] Check for highly correlated features. Sometimes we can drop highly correlated features, but before that, we should also test to see how they influence the model. Try all variants.\n",
        "- [x] Drop irrelevant features\n",
        "- [ ] Create new features/variables (i.e., proportions) \n",
        "- [ ] Feature Scaling: All features should be considered equally important before the algorithm's execution. \n",
        "- [ ] Separating Data Types: Numerical (Discrete, Continuous), Categorical(Ordinal, Nominal, Binary), Date/Time, Text, Image, Sound. \n",
        "          We can use select_dtypes() for example cat_df = df.select_dtypes(['object', 'bool']) and \n",
        "          num_df = df.select_dtypes(['int', 'float']) \n",
        "- [ ] Covert Data Types, if necessary\n",
        "\n",
        "Transforming Categorical Variables for Logistic Regression Models\n",
        "- [x] One-Hot Encoding for Categorical variables [Read](https://towardsdatascience.com/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769) and [Read](https://datascience.stackexchange.com/questions/18056/why-dont-tree-ensembles-require-one-hot-encoding) Remember its redundancy and keep only one of the encoded dummy variables.\n",
        "- [ ] Ordinal Encoding for any ordinal variables (Generally, label encoding is a bad idea, particularly for regression algorithms. Other algorithms may allow for unencoded categorial variables). OHE gives each nominal variable a column, but this doesn't make sense for ordinal variables. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4NPbEMTOApN"
      },
      "source": [
        "*Note to self: Explore how class imbalance leads to overfitting* <p>\n",
        "*Note to self: Explore application / distinguish applications of data wrangling methods on each new dataset* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iaXCk8IOApN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "78ba3b41-6301-48e5-c0ea-12b133b2662d"
      },
      "source": [
        "# Deal with Missing Values \n",
        "df.query('Tenure == 0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>15656300</td>\n",
              "      <td>Lucciano</td>\n",
              "      <td>411</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59697.17</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>53483.21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>36</td>\n",
              "      <td>15794171</td>\n",
              "      <td>Lombardo</td>\n",
              "      <td>475</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>45</td>\n",
              "      <td>0.0</td>\n",
              "      <td>134264.04</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27822.99</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>58</td>\n",
              "      <td>15647091</td>\n",
              "      <td>Endrizzi</td>\n",
              "      <td>725</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75888.20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45613.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>73</td>\n",
              "      <td>15812518</td>\n",
              "      <td>Palermo</td>\n",
              "      <td>657</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>37</td>\n",
              "      <td>0.0</td>\n",
              "      <td>163607.18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>44203.55</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>128</td>\n",
              "      <td>15782688</td>\n",
              "      <td>Piccio</td>\n",
              "      <td>625</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>148507.24</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46824.08</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9793</th>\n",
              "      <td>9794</td>\n",
              "      <td>15772363</td>\n",
              "      <td>Hilton</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101979.16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>90928.48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9799</th>\n",
              "      <td>9800</td>\n",
              "      <td>15722731</td>\n",
              "      <td>Manna</td>\n",
              "      <td>653</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>119556.10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>78250.13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9843</th>\n",
              "      <td>9844</td>\n",
              "      <td>15778304</td>\n",
              "      <td>Fan</td>\n",
              "      <td>646</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>92398.08</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18897.29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9868</th>\n",
              "      <td>9869</td>\n",
              "      <td>15587640</td>\n",
              "      <td>Rowntree</td>\n",
              "      <td>718</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>93143.39</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>167554.86</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9919</th>\n",
              "      <td>9920</td>\n",
              "      <td>15798084</td>\n",
              "      <td>Murray</td>\n",
              "      <td>688</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>105784.85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>382 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "29           30    15656300  Lucciano  ...               1        53483.21      0\n",
              "35           36    15794171  Lombardo  ...               0        27822.99      1\n",
              "57           58    15647091  Endrizzi  ...               0        45613.75      0\n",
              "72           73    15812518   Palermo  ...               1        44203.55      0\n",
              "127         128    15782688    Piccio  ...               0        46824.08      1\n",
              "...         ...         ...       ...  ...             ...             ...    ...\n",
              "9793       9794    15772363    Hilton  ...               0        90928.48      0\n",
              "9799       9800    15722731     Manna  ...               0        78250.13      1\n",
              "9843       9844    15778304       Fan  ...               1        18897.29      0\n",
              "9868       9869    15587640  Rowntree  ...               0       167554.86      0\n",
              "9919       9920    15798084    Murray  ...               0       105784.85      0\n",
              "\n",
              "[382 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0hjEq_APWwN"
      },
      "source": [
        "# display(df.query('Tenure.isna()'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY85Q27cOApO"
      },
      "source": [
        "In order to decide what to do with the 909 rows with missing Tenure information, we looked at the rows in detail and didn't find patterns or relationships in the data. We can choose to do any number of things, but in this case, we'll fill the missing values with the median of the Tenure data. The describe() function above showed us the median and mean are virtually the same, so in this case either measure of central tendency could work. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw9yrHl8OApO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "5617526b-35ad-411c-afc2-6219a98de349"
      },
      "source": [
        "df['Tenure'] = df['Tenure'].fillna(df['Tenure'].median())\n",
        "display(df.isna().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RowNumber          0\n",
              "CustomerId         0\n",
              "Surname            0\n",
              "CreditScore        0\n",
              "Geography          0\n",
              "Gender             0\n",
              "Age                0\n",
              "Tenure             0\n",
              "Balance            0\n",
              "NumOfProducts      0\n",
              "HasCrCard          0\n",
              "IsActiveMember     0\n",
              "EstimatedSalary    0\n",
              "Exited             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ecFQto8OApP"
      },
      "source": [
        "# Drop irrelevant features\n",
        "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Res23t5iOApT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b0ddef7d-1195-47d9-8820-72b17811dba7"
      },
      "source": [
        "# Transform Categorical Variables for Logistic Regression\n",
        "df = pd.get_dummies(df, drop_first = True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1.0</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8.0</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2.0</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Age  Tenure  ...  Geography_Germany  Geography_Spain  Gender_Male\n",
              "0          619   42     2.0  ...                  0                0            0\n",
              "1          608   41     1.0  ...                  0                1            0\n",
              "2          502   42     8.0  ...                  0                0            0\n",
              "3          699   39     1.0  ...                  0                0            0\n",
              "4          850   43     2.0  ...                  0                1            0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-bEIYVLOApU"
      },
      "source": [
        "We used get_dummies() to transform the two categorical variables (Geography and Gender). These categorical variables were both nominal, so we didn't have to do anything else to transform them. We'll move forward and use this processed dataset with our model training and study it's performance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeE1S1_5OApU"
      },
      "source": [
        "In looking at our checklist above, we can see that we still haven't investigated for highly correlated features or created any new features. In the next section, we'll choose to start training our models based off of the data and see how our dataset performs. We've already changed quite a bit and now would be a good time to dive into our model building and testing. We can always return to manipulate our dataset at a later time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9J0HHE7OApV"
      },
      "source": [
        "## Create Your Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHCDywI4OApV"
      },
      "source": [
        "- [ ] Set a radom state for reproduceable results\n",
        "- [ ] Separate features from target \n",
        "- [ ] Create three sets of data: a training set, validation set and testing set. The validation set will be used to test different hyperparameters while the testing set is used to check the performance of the model. \n",
        "- [ ] Check the size of the samples we created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YIrTSWZOApV"
      },
      "source": [
        "random_state = 93\n",
        "\n",
        "def split_data(data):\n",
        "    features, target = data.drop(columns=['Exited']), data['Exited']\n",
        "    \n",
        "    # 80% train and %20 test\n",
        "    features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2,random_state=42)\n",
        "    \n",
        "    # 80% train (of %80 train) and %20 validation\n",
        "    features_train, features_valid, target_train, target_valid = \\\n",
        "        train_test_split(features_train, target_train, test_size=0.2)\n",
        "    \n",
        "    return features_train, features_valid, features_test, \\\n",
        "           target_train, target_valid, target_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I9uaA9VOApW"
      },
      "source": [
        "features_train, features_valid, features_test, target_train, target_valid, target_test = split_data(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StWGshNqOApW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee4ce56-d900-4a5e-8054-8e9f8c5b1bdb"
      },
      "source": [
        "# Let's check sizes of samples\n",
        "assert features_train.shape[0] == target_train.shape[0]\n",
        "print(\"Training size: \", features_train.shape[0], target_train.shape[0])\n",
        "\n",
        "assert features_valid.shape[0] == target_valid.shape[0]\n",
        "print(\"Validation size: \",features_valid.shape[0], target_valid.shape[0])\n",
        "\n",
        "assert features_test.shape[0] == target_test.shape[0]\n",
        "print(\"Test size: \",features_test.shape[0], target_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size:  6400 6400\n",
            "Validation size:  1600 1600\n",
            "Test size:  2000 2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opeCJedxOApX"
      },
      "source": [
        "## Testing Models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w_W39XWOApX"
      },
      "source": [
        " - [x] Select a variety of classifiers for this classification model. In this project, we'll be trying out the Logistic Regression and Random Forest classifiers. \n",
        " - [ ] Set a radom state in building models for reproduceable results\n",
        " - [ ] Quick test using a preferred model of our choice. Test with the evaluation metrics we need. \n",
        " - [ ] Tune hyperparameters using validation set, and leveraging tools like GridSearchCV() \n",
        " - [ ] Check the accuracy (or the evaluation metric/s of your choice) on the models you are building. \n",
        " - [ ] Take note of the hyperparameters that resulted in the highest evaluation metric (i.e., n_estimators = 40) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1INbYqGOApY"
      },
      "source": [
        "Evaluation Metrics \n",
        "- [x] Choose the leading evaluation metric for your model. Consider\n",
        "    * Confusion Matrix (TP, FP, FN, TN) : confusion_matrix() \n",
        "    * Accuracy (\n",
        "    * Recall\n",
        "    * F1 Score \n",
        "    * Precision \n",
        "    * Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCqxPCV3OApY"
      },
      "source": [
        "Additional Data Processing\n",
        "\n",
        "Once we've created our different datasets, we can start to do other transformation steps to make our data work better with our model. At this point, since we have a set of data for training, that's the set of data that we'll use to consider:\n",
        "- [ ] Upsampling. When ratio of classes is far fom 1:1, our classes are imbalanced and will cause problems as we train the model.\n",
        "- [x] Downsampling. When ratio of classes is far fom 1:1, our classes are imbalanced and will cause problems as we train the model.\n",
        "- [ ] You can use the class_weight argument from sklearn to try to fix class imbalance \n",
        "- [ ] Generally, any methods to correct class Imbalance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc9V1AR7OApZ"
      },
      "source": [
        "Before we move on to building out other classifiers, it makes sense to do a rough test of one of our models and check to see what our preferred evaluation metrics tell us about the dataset/model. Depending on what we find, we might be inclined to return to some of our other available data transformation options, like scaling features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llzgHDo1OApZ"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjwPum4TOApZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224ce254-8244-4477-d484-675d2a091328"
      },
      "source": [
        "def train_LogReg_sanity_check(x_train, x_valid, y_train, y_valid): \n",
        "    model = LogisticRegression(solver = 'liblinear', random_state = random_state)\n",
        "    model.fit(x_train, y_train)\n",
        "    print('Accuracy:', model.score(x_valid, y_valid))\n",
        "    print('F1 Score:', f1_score(y_valid, model.predict(x_valid)))\n",
        "    print('AUC-ROC:', roc_auc_score(y_valid, model.predict_proba(x_valid)[:,1]))\n",
        "\n",
        "train_LogReg_sanity_check(features_train, features_valid, target_train, target_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.795\n",
            "F1 Score: 0.0989010989010989\n",
            "AUC-ROC: 0.6776739137519144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zey_2cg0OApa"
      },
      "source": [
        "Wow, that's quite a low F1 Score. Since that's the prioritized metric for this project, we'll now want to look at our data and see if there's are any other changes we can make to enhance our results. We'll also have the opportunity to look for improved perforance through tuning our preferred model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87HiXeTzOApa"
      },
      "source": [
        "### Class Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shWS1x2GOApb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b245ca-1b5d-42a2-bc83-980d80b339d8"
      },
      "source": [
        "# Check for class imbalance\n",
        "print(df['Exited'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    7963\n",
            "1    2037\n",
            "Name: Exited, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cavb4fYoOApb"
      },
      "source": [
        "One area we can make improvements in, is class imbalance. Our counts above show that clients who have not exited are overly represented. More than three times that of clients who have exited the bank. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK0Y4WsaOApb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3758aa4-557d-471a-8dbe-0f5db6e9fe89"
      },
      "source": [
        "# Balance class weights \n",
        "def train_LogReg_balanced_check(x_train, x_valid, y_train, y_valid, class_weight = None): \n",
        "    model = LogisticRegression(class_weight = class_weight, solver = 'liblinear', random_state = random_state)\n",
        "    model.fit(x_train, y_train)\n",
        "    print('Accuracy:', model.score(x_valid, y_valid))\n",
        "    print('F1 Score:', f1_score(y_valid, model.predict(x_valid)))\n",
        "    print('AUC-ROC:', roc_auc_score(y_valid, model.predict_proba(x_valid)[:,1]))\n",
        "\n",
        "train_LogReg_balanced_check(features_train, features_valid, target_train, target_valid, 'balanced')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.676875\n",
            "F1 Score: 0.454065469904963\n",
            "AUC-ROC: 0.722873565811606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz1M6lhSOApc"
      },
      "source": [
        "Great! Using class_weight resulted in a jump in F1 Score. Let's try another method for fixing class imbalance and test again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvUwtdksOApc"
      },
      "source": [
        "def downsample(features, target, fraction):\n",
        "    features_zeros = features[target == 0]\n",
        "    features_ones = features[target == 1]\n",
        "    target_zeros = target[target == 0]\n",
        "    target_ones = target[target == 1]\n",
        "\n",
        "    features_downsampled = pd.concat(\n",
        "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
        "    target_downsampled = pd.concat(\n",
        "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
        "    \n",
        "    features_downsampled, target_downsampled = shuffle(\n",
        "        features_downsampled, target_downsampled, random_state=12345)\n",
        "    \n",
        "    return features_downsampled, target_downsampled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVqx8buBOApd"
      },
      "source": [
        "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC72BK3cOApd"
      },
      "source": [
        "*Note to self: Explore alternate methods for downsampling*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l3CaYIrOApd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c0e0bb-e060-4409-f620-42fe6a3fa484"
      },
      "source": [
        "# Balance class weights \n",
        "def train_LogReg_downsampled_check(x_train, x_valid, y_train, y_valid, class_weight = None): \n",
        "    model = LogisticRegression(class_weight = class_weight, solver = 'liblinear', random_state = random_state)\n",
        "    model.fit(x_train, y_train)\n",
        "    print('Accuracy:', model.score(x_valid, y_valid))\n",
        "    print('F1 Score:', f1_score(y_valid, model.predict(x_valid)))\n",
        "    print('AUC-ROC:', roc_auc_score(y_valid, model.predict_proba(x_valid)[:,1]))\n",
        "\n",
        "train_LogReg_downsampled_check(features_downsampled, features_valid, target_downsampled, target_valid, 'balanced')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.659375\n",
            "F1 Score: 0.43523316062176165\n",
            "AUC-ROC: 0.7044111711901413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE7XeFQ6OApd"
      },
      "source": [
        "Now, back to other data processing we can do - feature scaling. We can see that our quantitative data has different scales. Some range between 1 to 10 and others have a much wider range. This type of difference can negatively affect how the Logistical Regression model learns from our data. Let's use StandardScaler() to help us scale these features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2_a9yDSOApe"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zycnE9hiOApe"
      },
      "source": [
        "# Scale features_train\n",
        "numeric = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'Tenure', 'NumOfProducts']\n",
        "scaler = StandardScaler() \n",
        "scaler.fit(features_train[numeric])\n",
        "features_train.loc[:,numeric] = scaler.transform(features_train[numeric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEkKKKeTOApe"
      },
      "source": [
        "# Scale features_valid\n",
        "numeric = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'Tenure', 'NumOfProducts']\n",
        "scaler = StandardScaler() \n",
        "scaler.fit(features_valid[numeric])\n",
        "features_valid.loc[:,numeric] = scaler.transform(features_valid[numeric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU_dK19QOApe"
      },
      "source": [
        "# Scale features_test\n",
        "numeric = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'Tenure', 'NumOfProducts']\n",
        "scaler = StandardScaler() \n",
        "scaler.fit(features_test[numeric])\n",
        "features_test.loc[:,numeric] = scaler.transform(features_test[numeric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0DzoIJzOApf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0fa6ae-bb3b-4f39-acd8-e7e61c4e1dc2"
      },
      "source": [
        "def train_LogReg_balanced_scale_check(x_train, x_valid, y_train, y_valid, class_weight = None): \n",
        "    model = LogisticRegression(class_weight = class_weight, solver = 'liblinear', random_state = random_state)\n",
        "    model.fit(x_train, y_train)\n",
        "    print('Accuracy:', model.score(x_valid, y_valid))\n",
        "    print('F1 Score:', f1_score(y_valid, model.predict(x_valid)))\n",
        "    print('AUC-ROC:', roc_auc_score(y_valid, model.predict_proba(x_valid)[:,1]))\n",
        "\n",
        "train_LogReg_balanced_scale_check(features_train, features_valid, target_train, target_valid, 'balanced')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.709375\n",
            "F1 Score: 0.4709897610921501\n",
            "AUC-ROC: 0.7634632594586871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5aUt1PsOApf"
      },
      "source": [
        "Hmm, we're still not getting close to the F1 Score we'd like to see (.59). Let's start trying a different classifier - Random Forest. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7KvFSW5OApf"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7cFkuYJOApg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0983bcc9-46a2-4d38-c085-6a4ecf53183d"
      },
      "source": [
        "def tree_model(x_train, x_valid, y_train, y_valid): \n",
        "    model = RandomForestClassifier(random_state = random_state, n_estimators = 100) \n",
        "    model.fit(x_train, y_train)\n",
        "    print('Accuracy:', model.score(x_valid, y_valid))\n",
        "    print('F1 Score:', f1_score(y_valid, model.predict(x_valid)))\n",
        "    print('AUC-ROC:', roc_auc_score(y_valid, model.predict_proba(x_valid)[:,1]))\n",
        "    \n",
        "tree_model(features_train, features_valid, target_train, target_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.873125\n",
            "F1 Score: 0.598019801980198\n",
            "AUC-ROC: 0.8536357004805487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NbjECq2OApg"
      },
      "source": [
        "We've got promising results! Let's dig into the Random Forest classifier and look for the best parameters using GridSearchCV. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2icWKLdOApg"
      },
      "source": [
        "random_forest = RandomForestClassifier(random_state=random_state, class_weight = 'balanced')\n",
        "random_params = {'n_estimators':range(1,100,5), 'max_depth':range(1,15, 1)}\n",
        "grid_search = GridSearchCV(estimator = random_forest,\n",
        "                          param_grid = random_params)\n",
        "grid_search = grid_search.fit(features_train, target_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqLklTlWOAph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e6481d-1b14-44f9-88f3-8a9adf114ecc"
      },
      "source": [
        "accuracy = grid_search.best_score_\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8534375000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neklP9P-OAph"
      },
      "source": [
        "Instead of accuracy, could the code above be for f1? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYlGCZH2OAph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952a48c6-3381-47bf-b29e-42a2eae2c188"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 14, 'n_estimators': 61}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Ad1qizOApi"
      },
      "source": [
        "## Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZNs75DOOApi"
      },
      "source": [
        "- [x] For Logistic Regression, consider adjusting the classification threshold. This model computes the probability of classes, and the line where the negative class ends and the positive class begins is called the threshold. By default, it is .5, but we can change it. \n",
        "- [x] For Logistic Regression, consider studying the PR (Precision-Recall) Curve. \n",
        "- [x] For Logistic Regression, consider studying thr ROC Curve, where TPR is plotted along on the y-axis and FPR is plotted along the x-axis. For a model that always answers randomly, the ROC curve is a diagonal line foing from the lower left to the upper right. The higher the curve, the greater the TPR value and the better the model's quaity. \n",
        "- [x] For Logistic Regression, and to find out how much our model differs from the random model, let's calculate the AUC-ROC value. This metric ranges from 0 to 1, where the AUC-ROC value for a random model is .5. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ6YpE3-OApi"
      },
      "source": [
        "* Underfitting occurs when accuracy is low and approximately the same for both the training and test sets. \n",
        "* Overfitting occus when we or the model sees dependencies where there aren't any. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t04f79APOApj"
      },
      "source": [
        "def tree_model(model, x_train, x_valid, y_train, y_valid, x_test, y_test): \n",
        "    model = RandomForestClassifier(random_state = random_state, n_estimators = 46, max_depth = 13, class_weight = 'balanced')\n",
        "    model.fit(x_train, y_train)\n",
        "    print('Accuracy:', model.score(x_valid, y_valid))\n",
        "    print('F1 Score:', f1_score(y_valid, model.predict(x_valid)))\n",
        "    print('AUC-ROC:', roc_auc_score(y_valid, model.predict_proba(x_valid)[:,1]))\n",
        "    \n",
        "    print('Accuracy:', model.score(x_test, y_test))\n",
        "    print('F1 Score:', f1_score(y_test, model.predict(x_test)))\n",
        "    print('AUC-ROC:', roc_auc_score(y_test, model.predict_proba(x_test)[:,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhvqf6f-OApj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f9838a-c60c-403d-ef88-f133224ee395"
      },
      "source": [
        "tree_model(grid_search, features_train, features_valid, target_train, target_valid, features_test, target_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.863125\n",
            "F1 Score: 0.5936920222634507\n",
            "AUC-ROC: 0.8459800109796727\n",
            "Accuracy: 0.8575\n",
            "F1 Score: 0.6013986013986014\n",
            "AUC-ROC: 0.853495600513656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFgMhDRHOApk"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzI-7GLFOApl"
      },
      "source": [
        "Through several rounds of testing and tuning models, and then finally digging into the Random Forest model with GridSearchCV, we were able to identify ideal parameters. The model that we chose gives us an F1 score above .59 when tested against the validation and testing datasets. Also, the AUC-ROC score is .85 and indicates that the classifier is able to distinguish between classes. "
      ]
    }
  ]
}